{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Start with the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.compat.v2 as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Dataset import\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masg\\Anaconda3\\envs\\hls4ml\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape (17140, 35000, 1), Train Y shape (17140,)\n",
      "Test X shape (709, 35000, 1), Test Y shape (709,)\n",
      "Valid X shape (4297, 35000, 1), Test Y shape (4297,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#NOTE invert channel position for keras w.r.t pytorch\n",
    "train_data_torch = torch.load('../UltraWood/data/databases/train_data_torch_main.pt').float()\n",
    "train_data_torch = (train_data_torch-torch.mean(train_data_torch,2,keepdim=True))/torch.max(train_data_torch,2,keepdim=True)[0]    \n",
    "train_data_tf = tf.convert_to_tensor(train_data_torch.permute(0,2,1).numpy())\n",
    "train_targets_torch = torch.load('../UltraWood/data/databases/train_targets_torch_main.pt')\n",
    "train_targets_tf = tf.convert_to_tensor(train_targets_torch.numpy())\n",
    "\n",
    "test_data_torch = torch.load('../UltraWood/data/databases/test_data_torch_main.pt').float()\n",
    "test_data_torch = (test_data_torch-torch.mean(test_data_torch,2,keepdim=True))/torch.max(test_data_torch,2,keepdim=True)[0]    \n",
    "test_data_tf = tf.convert_to_tensor(test_data_torch.permute(0,2,1).numpy())\n",
    "test_targets_torch = torch.load('../UltraWood/data/databases/test_targets_torch_main.pt')\n",
    "test_targets_tf = tf.convert_to_tensor(test_targets_torch.numpy())\n",
    "\n",
    "valid_data_torch = torch.load('../UltraWood/data/databases/valid_data_torch_main.pt').float()\n",
    "valid_data_torch = (valid_data_torch-torch.mean(valid_data_torch,2,keepdim=True))/torch.max(valid_data_torch,2,keepdim=True)[0]    \n",
    "valid_data_tf = tf.convert_to_tensor(valid_data_torch.permute(0,2,1).numpy())\n",
    "valid_targets_torch = torch.load('../UltraWood/data/databases/valid_targets_torch_main.pt')\n",
    "valid_targets_tf = tf.convert_to_tensor(valid_targets_torch.numpy())\n",
    "\n",
    "print(f\"Train X shape {train_data_tf.shape}, Train Y shape {train_targets_tf.shape}\\nTest X shape {test_data_tf.shape}, Test Y shape {test_targets_tf.shape}\")\n",
    "print(f\"Valid X shape {valid_data_tf.shape}, Test Y shape {valid_targets_tf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "batch_size = 1024\n",
    "\n",
    "train_data = train_data_tf.shuffle(4096).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for example in train_data.take(1):\n",
    "    break\n",
    "print(\"X train batch shape = {}, Y train batch shape = {} \".format(example[0].shape, example[1].shape))\n",
    "\n",
    "val_data = test_data_tf.batch(batch_size)\n",
    "val_data = val_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "'''\n",
    "classes = [\"dry\", \"semi\", \"wet\"]\n",
    "\n",
    "#train_data_tf = train_data_tf.reshape([train_data_tf.shape[0], train_data_tf.shape[2], 1])\n",
    "#train_targets_tf = train_targets_tf.reshape([train_targets_tf.shape[0], train_targets_tf.shape[2], 1])\n",
    "train_targets_tf = tf.keras.utils.to_categorical(train_targets_tf, num_classes=len(classes))\n",
    "test_targets_tf = tf.keras.utils.to_categorical(test_targets_tf, num_classes=len(classes))\n",
    "valid_targets_tf = tf.keras.utils.to_categorical(valid_targets_tf, num_classes=len(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Defining the model\n",
    "\n",
    "We then need to define a model. For the lowest possible latency, each layer should have a maximum number of trainable parameters of 4096. This is due to fixed limits in the Vivado compiler, beyond which maximally unrolled (=parallel) compilation will fail. This will allow us to use `strategy = 'latency'` in the hls4ml part, rather than `strategy = 'resource'`, in turn resulting in lower latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, AvgPool1D, ReLU, Flatten, Dense, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1090, 32)          4128      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1090, 32)          0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 545, 32)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 32)            65568     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 31, 32)            0         \n",
      "                                                                 \n",
      " average_pooling1d_1 (Averag  (None, 15, 32)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 480)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 4329      \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 9)                 0         \n",
      "                                                                 \n",
      " output_dense (Dense)        (None, 3)                 30        \n",
      "                                                                 \n",
      " output_softmax (Softmax)    (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,055\n",
      "Trainable params: 74,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=128, strides=32, input_shape=(35000, 1)))\n",
    "model.add(ReLU())\n",
    "model.add(AvgPool1D(pool_size=2, strides=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=64, strides=16))\n",
    "model.add(ReLU())\n",
    "model.add(AvgPool1D(pool_size=2, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(9))\n",
    "model.add(ReLU())\n",
    "model.add(Dense(3, name='output_dense'))\n",
    "model.add(Softmax(name=\"output_softmax\"))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Lets check if this model can be implemented completely unrolled (=parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d: 4096\n",
      "conv1d_1: 65536\n",
      "Layer conv1d_1 is too large (65536), are you sure you want to train?\n",
      "dense: 4320\n",
      "Layer dense is too large (4320), are you sure you want to train?\n",
      "output_dense: 27\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.__class__.__name__ in ['Conv1D', 'Dense']:\n",
    "        w = layer.get_weights()[0]\n",
    "        layersize = np.prod(w.shape)\n",
    "        print(\"{}: {}\".format(layer.name,layersize)) # 0 = weights, 1 = biases\n",
    "        if (layersize > 4096): # assuming that shape[0] is batch, i.e., 'None'\n",
    "            print(\"Layer {} is too large ({}), are you sure you want to train?\".format(layer.name,layersize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Looks good! It's below the Vivado-enforced unroll limit of 4096.\n",
    "\n",
    "## Prune dense and convolutional layers\n",
    "Since we've seen in the previous notebooks that pruning can be done at no accuracy cost, let's prune the convolutional and dense layers to 50% sparsity, skipping the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps per epoch is 482\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "\n",
    "\n",
    "NSTEPS = int(train_data_tf.shape[0]*0.9)  // batch_size #90% train, 10% validation in 10-fold cross validation\n",
    "print('Number of training steps per epoch is {}'.format(NSTEPS))\n",
    "\n",
    "# Prune all convolutional and dense layers gradually from 0 to 50% sparsity every 2 epochs, \n",
    "# ending by the 10th epoch\n",
    "def pruneFunction(layer):\n",
    "    pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity = 0.0,\n",
    "                                                                   final_sparsity = 0.50, \n",
    "                                                                   begin_step = NSTEPS*2, \n",
    "                                                                   end_step = NSTEPS*10, \n",
    "                                                                   frequency = NSTEPS)\n",
    "                     }\n",
    "    if isinstance(layer, tf.keras.layers.Conv1D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name!='output_dense':\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)  \n",
    "    return layer\n",
    "\n",
    "model_pruned = tf.keras.models.clone_model( model, clone_function=pruneFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Train baseline\n",
    "\n",
    "We're now ready to train the model! We defined the batch size and n epochs above. We won't use callbacks that store the best weights only, since this might select a weight configuration that has not yet reached 50% sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False # True if you want to retrain, false if you want to load a previsously trained model\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "if train:\n",
    "    \n",
    "    LOSS        = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3e-3)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=20, verbose=1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=30, verbose=1)\n",
    "            ] \n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(x=train_data_tf,\n",
    "                     y=train_targets_tf,\n",
    "                     batch_size=batch_size,\n",
    "                     validation_data=(valid_data_tf, valid_targets_tf),\n",
    "                     epochs = n_epochs,\n",
    "                     callbacks = callbacks)   \n",
    "    end = time.time()\n",
    "\n",
    "    print('It took {} minutes to train Keras model'.format( (end - start)/60.))\n",
    "    \n",
    "    model.save('cnn_model.h5')\n",
    "\n",
    "else:\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "    \n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n",
    "    model_pruned = tf.keras.models.load_model('cnn_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "536/536 [==============================] - 12s 14ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 7.3945e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 2/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 6.2391e-04 - accuracy: 1.0000 - val_loss: 5.4686e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 3/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 4.5283e-04 - accuracy: 1.0000 - val_loss: 4.0371e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 4/30\n",
      "536/536 [==============================] - 7s 14ms/step - loss: 3.2826e-04 - accuracy: 1.0000 - val_loss: 2.9839e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 5/30\n",
      "536/536 [==============================] - 6s 11ms/step - loss: 2.4528e-04 - accuracy: 1.0000 - val_loss: 2.1936e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 6/30\n",
      "536/536 [==============================] - 7s 14ms/step - loss: 1.7734e-04 - accuracy: 1.0000 - val_loss: 1.6328e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 7/30\n",
      "536/536 [==============================] - 6s 12ms/step - loss: 1.3455e-04 - accuracy: 1.0000 - val_loss: 1.2100e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 8/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 9.9489e-05 - accuracy: 1.0000 - val_loss: 1.0285e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 9/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 7.4487e-05 - accuracy: 1.0000 - val_loss: 6.7661e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 10/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 5.6296e-05 - accuracy: 1.0000 - val_loss: 5.1629e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 11/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 4.2598e-05 - accuracy: 1.0000 - val_loss: 3.9187e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 12/30\n",
      "536/536 [==============================] - 6s 11ms/step - loss: 3.2311e-05 - accuracy: 1.0000 - val_loss: 3.0020e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 13/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 2.6288e-05 - accuracy: 1.0000 - val_loss: 2.2771e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 14/30\n",
      "536/536 [==============================] - 6s 12ms/step - loss: 1.8557e-05 - accuracy: 1.0000 - val_loss: 1.7382e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 15/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 1.4292e-05 - accuracy: 1.0000 - val_loss: 1.3132e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 16/30\n",
      "536/536 [==============================] - 7s 14ms/step - loss: 1.0892e-05 - accuracy: 1.0000 - val_loss: 1.0385e-05 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 17/30\n",
      "536/536 [==============================] - 7s 12ms/step - loss: 8.4556e-06 - accuracy: 1.0000 - val_loss: 7.7487e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 18/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 6.3805e-06 - accuracy: 1.0000 - val_loss: 5.8769e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 19/30\n",
      "536/536 [==============================] - 6s 12ms/step - loss: 4.9105e-06 - accuracy: 1.0000 - val_loss: 4.5202e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 20/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 3.7167e-06 - accuracy: 1.0000 - val_loss: 3.5296e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 21/30\n",
      "536/536 [==============================] - 7s 12ms/step - loss: 2.8849e-06 - accuracy: 1.0000 - val_loss: 2.6652e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 22/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 2.1855e-06 - accuracy: 1.0000 - val_loss: 2.0500e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 23/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 1.6971e-06 - accuracy: 1.0000 - val_loss: 1.5604e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 24/30\n",
      "536/536 [==============================] - 6s 12ms/step - loss: 1.2903e-06 - accuracy: 1.0000 - val_loss: 1.2050e-06 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 25/30\n",
      "536/536 [==============================] - 7s 14ms/step - loss: 1.0067e-06 - accuracy: 1.0000 - val_loss: 9.2163e-07 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 26/30\n",
      "536/536 [==============================] - 6s 11ms/step - loss: 7.5893e-07 - accuracy: 1.0000 - val_loss: 7.0402e-07 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 27/30\n",
      "536/536 [==============================] - 7s 14ms/step - loss: 5.8283e-07 - accuracy: 1.0000 - val_loss: 5.4278e-07 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 28/30\n",
      "536/536 [==============================] - 7s 12ms/step - loss: 4.4654e-07 - accuracy: 1.0000 - val_loss: 4.1267e-07 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 29/30\n",
      "536/536 [==============================] - 7s 13ms/step - loss: 3.4431e-07 - accuracy: 1.0000 - val_loss: 3.1529e-07 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 30/30\n",
      "536/536 [==============================] - 7s 12ms/step - loss: 2.6597e-07 - accuracy: 1.0000 - val_loss: 2.5628e-07 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "It took 3.460363841056824 minutes to train Keras model\n"
     ]
    }
   ],
   "source": [
    "train = True # True if you want to retrain, false if you want to load a previsously trained model\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "if train:\n",
    "    \n",
    "    LOSS        = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3e-3)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "    model_pruned.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=20, verbose=1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=30, verbose=1),\n",
    "            pruning_callbacks.UpdatePruningStep()\n",
    "            ] \n",
    "\n",
    "    start = time.time()\n",
    "    model_pruned.fit(x=train_data_tf,\n",
    "                     y=train_targets_tf,\n",
    "                     batch_size=batch_size,\n",
    "                     validation_data=(valid_data_tf, valid_targets_tf),\n",
    "                     epochs = n_epochs,\n",
    "                     callbacks = callbacks)   \n",
    "    end = time.time()\n",
    "\n",
    "    print('It took {} minutes to train Keras model'.format( (end - start)/60.))\n",
    "    \n",
    "    model_pruned.save('pruned_cnn_model.h5')\n",
    "\n",
    "else:\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "    \n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n",
    "    model_pruned = tf.keras.models.load_model('pruned_cnn_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 17ms/step - loss: 75.7289 - accuracy: 0.0000e+00\n",
      "Keras accuracy = 0.0\n"
     ]
    }
   ],
   "source": [
    "test_score_baseline = model_pruned.evaluate(test_data_tf, test_targets_tf)\n",
    "print('Keras accuracy = {}'.format(test_score_baseline[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 11ms/step\n",
      "[[  0   0   0]\n",
      " [532   0   0]\n",
      " [177   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_prediction = model.predict(test_data_tf)\n",
    "y_prediction = np.argmax(y_prediction, axis = 1)\n",
    "y_test = np.argmax(test_targets_tf, axis=1)\n",
    "#Create confusion matrix \n",
    "result = confusion_matrix(y_test, y_prediction)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n",
      "0 2\n"
     ]
    }
   ],
   "source": [
    "for pred, gt in zip(y_prediction,y_test):\n",
    "    print(pred, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv1d: % of zeros = 0.0\n",
      "Layer conv1d_1: % of zeros = 0.0\n",
      "Layer dense: % of zeros = 0.0\n",
      "Layer output_dense: % of zeros = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def doWeights(model):\n",
    "\n",
    "    allWeightsByLayer = {}\n",
    "    for layer in model.layers:\n",
    "        if (layer._name).find(\"batch\")!=-1 or len(layer.get_weights())<1:\n",
    "            continue \n",
    "        weights=layer.weights[0].numpy().flatten()  \n",
    "        allWeightsByLayer[layer._name] = weights\n",
    "        print('Layer {}: % of zeros = {}'.format(layer._name,np.sum(weights==0)/np.size(weights)))\n",
    "\n",
    "    labelsW = []\n",
    "    histosW = []\n",
    "\n",
    "    for key in reversed(sorted(allWeightsByLayer.keys())):\n",
    "        labelsW.append(key)\n",
    "        histosW.append(allWeightsByLayer[key])\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    bins = np.linspace(-1.5, 1.5, 50)\n",
    "    plt.hist(histosW,bins,histtype='stepfilled',stacked=True,label=labelsW, edgecolor='black')\n",
    "    plt.legend(frameon=False,loc='upper left')\n",
    "    plt.ylabel('Number of Weights')\n",
    "    plt.xlabel('Weights')\n",
    "    plt.figtext(0.2, 0.38,model._name, wrap=True, horizontalalignment='left',verticalalignment='center')\n",
    "    \n",
    "doWeights(model_pruned) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## CNNs in hls4ml\n",
    "\n",
    "In this part, we will take the two models we trained above (the floating-point 32 Keras model and the 6-bit QKeras model), and synthesize them with hls4ml. Although your models are probably already in memory, let's load them from scratch. We need to pass the appropriate custom QKeras/pruning layers when loading, and remove the pruning parameters that were saved together with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n",
    "\n",
    "model = tf.keras.models.load_model('pruned_cnn_model.h5',custom_objects=co)\n",
    "model  = strip_pruning(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define the hls4ml and Vivado configurations. Two things will change with respect to what was done in the previous exercises. First, we will use ``IOType= 'io_stream'`` in the Vivado configuration.\n",
    "\n",
    "---\n",
    "****You must use ``IOType= 'io_stream'`` if attempting to synthesize a convolutional neural network.****\n",
    "\n",
    "---\n",
    "The CNN implementation in hls4ml is based on streams, which are synthesized in hardware as first in, first out (FIFO) buffers. Shift registers are used to keep track of the last  ``<kernel height - 1>`` rows of input pixels, and maintains a shifting snapshot of the convolution kernel.\n",
    "\n",
    "This is illustrated  in the gif below. Here, the input image is at the top-left and the output image at the bottom left. The top right image shows the internal state of the shift registers and convolutional kernel. The red square indicates the current pixels contained within the convolutional kernel.\n",
    "\n",
    "![alt text](images/conv2d_animation.gif \"The implementation of convolutional layers in hls4ml.\")\n",
    "\n",
    "Lastly, we will use ``['Strategy'] = 'Latency'`` for all the layers in the hls4ml configuration. If one layer would have >4096 elements, we sould set ``['Strategy'] = 'Resource'`` for that layer, or increase the reuse factor by hand. You can find examples of how to do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv1d_input, layer type: Input\n",
      "Layer name: conv1d, layer type: Conv1D\n",
      "  -> Activation (linear), layer name: conv1d\n",
      "Layer name: re_lu, layer type: ReLU\n",
      "Layer name: average_pooling1d, layer type: AveragePooling1D\n",
      "Layer name: conv1d_1, layer type: Conv1D\n",
      "  -> Activation (linear), layer name: conv1d_1\n",
      "Layer name: re_lu_1, layer type: ReLU\n",
      "Layer name: average_pooling1d_1, layer type: AveragePooling1D\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense\n",
      "Layer name: re_lu_2, layer type: ReLU\n",
      "Layer name: output_dense, layer type: Dense\n",
      "  -> Activation (linear), layer name: output_dense\n",
      "Layer name: output_softmax, layer type: Softmax\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       4\n",
      "  Strategy:          Latency\n",
      "LayerName\n",
      "  conv1d_input\n",
      "    Precision\n",
      "      result:        ap_fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     4\n",
      "  conv1d\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    Strategy:        Resource\n",
      "  conv1d_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  re_lu\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  average_pooling1d\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     4\n",
      "  conv1d_1\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    Strategy:        Resource\n",
      "  conv1d_1_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  re_lu_1\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  average_pooling1d_1\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     4\n",
      "  dense\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    Strategy:        Resource\n",
      "  dense_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  re_lu_2\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  output_dense\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    Strategy:        Resource\n",
      "  output_dense_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Resource\n",
      "  output_softmax\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     4\n",
      "    table_size:      1024\n",
      "    exp_table_t:     ap_fixed<18,8,AP_RND,AP_SAT>\n",
      "    inv_table_t:     ap_fixed<18,8,AP_RND,AP_SAT>\n",
      "    Strategy:        Stable\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv1d_input, layer type: InputLayer, input shapes: [[None, 35000, 1]], output shape: [None, 35000, 1]\n",
      "Layer name: conv1d, layer type: Conv1D, input shapes: [[None, 35000, 1]], output shape: [None, 1090, 32]\n",
      "Layer name: re_lu, layer type: Activation, input shapes: [[None, 1090, 32]], output shape: [None, 1090, 32]\n",
      "Layer name: average_pooling1d, layer type: AveragePooling1D, input shapes: [[None, 1090, 32]], output shape: [None, 545, 32]\n",
      "Layer name: conv1d_1, layer type: Conv1D, input shapes: [[None, 545, 32]], output shape: [None, 31, 32]\n",
      "Layer name: re_lu_1, layer type: Activation, input shapes: [[None, 31, 32]], output shape: [None, 31, 32]\n",
      "Layer name: average_pooling1d_1, layer type: AveragePooling1D, input shapes: [[None, 31, 32]], output shape: [None, 15, 32]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 15, 32]], output shape: [None, 480]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 480]], output shape: [None, 9]\n",
      "Layer name: re_lu_2, layer type: Activation, input shapes: [[None, 9]], output shape: [None, 9]\n",
      "Layer name: output_dense, layer type: Dense, input shapes: [[None, 9]], output shape: [None, 3]\n",
      "Layer name: output_softmax, layer type: Softmax, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Creating HLS model\n",
      "WARNING: Strategy for layer conv1d_input set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer conv1d set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer conv1d_linear set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer re_lu set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer average_pooling1d set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer conv1d_1 set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer conv1d_1_linear set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer re_lu_1 set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer average_pooling1d_1 set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer dense set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer dense_linear set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer re_lu_2 set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer output_dense set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Strategy for layer output_dense_linear set to \"Resource\", while model strategy set to \"Latency\".\n",
      "WARNING: Changing model strategy to \"Resource\"\n",
      "WARNING: Invalid ReuseFactor=4 with \"Resource\" strategy in layer \"output_dense\". Using ReuseFactor=3 instead. Valid ReuseFactor(s): 3,9,27.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to compile project \"myproject\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXilinxPart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxc7z020clg400-1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m hls_model \u001b[38;5;241m=\u001b[39m hls4ml\u001b[38;5;241m.\u001b[39mconverters\u001b[38;5;241m.\u001b[39mkeras_to_hls(cfg)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mhls_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\hls4ml\\model\\hls_model.py:534\u001b[0m, in \u001b[0;36mHLSModel.compile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbash build_lib.sh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret_val \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to compile project \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_project_name()))\n\u001b[0;32m    535\u001b[0m lib_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirmware/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.so\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_project_name(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_config_value(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStamp\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top_function_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mException\u001b[0m: Failed to compile project \"myproject\""
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "#First, the baseline model\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "# Set the precision and reuse factor for the full model\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config['Model']['ReuseFactor'] = 4\n",
    "\n",
    "# Create an entry for each layer, here you can for instance change the strategy for a layer to 'resource' \n",
    "# or increase the reuse factor individually for large layers.\n",
    "# In this case, we designed the model to be small enough for a fully parallel implementation \n",
    "# so we use the latency strategy and reuse factor of 1 for all layers.\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 4\n",
    "#If you want best numerical performance for high-accuray models, while the default latency strategy is faster but numerically more unstable\n",
    "hls_config['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config)\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "cfg['IOType']     = 'io_stream' # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir']  = 'pruned_cnn/'\n",
    "cfg['XilinxPart'] = \"xc7z020clg400-1\"\n",
    "  \n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's get a nice overview over the various shapes and precisions used for each layer through ``hls4ml.utils.plot_model``, as well as look at the weight profile using ``hls4ml.model.profiling.numerical``. The weight profiling returns two plots: Before (top) and after (bottom) various optimizations applied to the HLS model before the final translation to HLS, for instance the fusing of Dense and BatchNormalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.model.profiling.numerical(model=model, hls_model=hls_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The colored boxes are the distribution of the weights of the model, and the gray band illustrates the numerical range covered by the chosen fixed point precision. As we configured, this model uses a precision of ``ap_fixed<16,6>`` for all layers of the model. Let's now build our QKeras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Accuracy with bit-accurate emulation \n",
    "Let's check that the hls4ml accuracy matches the original. This usually takes some time, so let's do it over a reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = test_data_tf[:3000]\n",
    "Y_test_reduced = test_targets_tf[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict        = model.predict(X_test_reduced)\n",
    "y_predict_hls4ml = hls_model.predict(np.ascontiguousarray(X_test_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plotROC(Y, y_pred, y_pred_hls4ml, label=\"Model\"):\n",
    "    \n",
    "    accuracy_keras  = float(accuracy_score (np.argmax(Y,axis=1), np.argmax(y_pred,axis=1)))\n",
    "    accuracy_hls4ml = float(accuracy_score (np.argmax(Y,axis=1), np.argmax(y_pred_hls4ml,axis=1)))\n",
    "\n",
    "    print(\"Accuracy Keras:  {}\".format(accuracy_keras))\n",
    "    print(\"Accuracy hls4ml: {}\".format(accuracy_hls4ml))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9, 9))\n",
    "    _ = plotting.makeRoc(Y, y_pred, labels=['%i'%nr for nr in range(n_classes)])\n",
    "    plt.gca().set_prop_cycle(None) # reset the colors\n",
    "    _ = plotting.makeRoc(Y, y_pred_hls4ml, labels=['%i'%nr for nr in range(n_classes)], linestyle='--')\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    lines = [Line2D([0], [0], ls='-'),\n",
    "             Line2D([0], [0], ls='--')]\n",
    "    from matplotlib.legend import Legend\n",
    "    leg = Legend(ax, lines, labels=['Keras', 'hls4ml'],\n",
    "                loc='lower right', frameon=False)\n",
    "    ax.add_artist(leg)\n",
    "    plt.figtext(0.2, 0.38,label, wrap=True, horizontalalignment='left',verticalalignment='center')\n",
    "    plt.ylim(0.01,1.)\n",
    "    plt.xlim(0.7,1.)\n",
    "\n",
    "# Plot the pruned floating point model:    \n",
    "plotROC(Y_test_reduced,y_predict,y_predict_hls4ml,label=\"Keras\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Looks good! Let's synthesize the models. \n",
    "## Logic synthesis\n",
    "This takes quite a while for CNN models, up to one hour for the models considered here. In the interest of time, we have therefore provided the neccessary reports for the models considered. You can also synthesize them yourself if you have time, and as usual follow the progress using ``tail -f pruned_cnn/vivado_hls.log`` and ``tail -f quantized_pruned_cnn/vivado_hls.log``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = False # Only if you want to synthesize the models yourself (>1h per model) rather than look at the provided reports.\n",
    "if synth:\n",
    "    hls_model.build(csim=False, synth=True, vsynth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We extract the latency from the C synthesis, namely the report in ```<project_dir>/myproject_prj/solution1/syn/report/myproject_csynth.rpt```. A more accurate latency estimate can be obtained from running cosim by passing ```hls_model.build(csim=False, synth=True, vsynth=True, cosim=True)``` ( = C/RTL cosimulation, synthesised HLS code is run on a simulator and tested on C test bench) but this takes a lot of time so we will skip it here.\n",
    "The resource estimates are obtained from the Vivado logic synthesis, and can be extracted from the report in ```<project_dir>/vivado_synth.rpt```. Let's fetch the most relevant numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReports(indir):\n",
    "    data_ = {}\n",
    "    \n",
    "    report_vsynth = Path('{}/vivado_synth.rpt'.format(indir))\n",
    "    report_csynth = Path('{}/myproject_prj/solution1/syn/report/myproject_csynth.rpt'.format(indir))\n",
    "    \n",
    "    if report_vsynth.is_file() and report_csynth.is_file():\n",
    "        print('Found valid vsynth and synth in {}! Fetching numbers'.format(indir))\n",
    "        \n",
    "        # Get the resources from the logic synthesis report \n",
    "        with report_vsynth.open() as report:\n",
    "            lines = np.array(report.readlines())\n",
    "            data_['lut']     = int(lines[np.array(['CLB LUTs*' in line for line in lines])][0].split('|')[2])\n",
    "            data_['ff']      = int(lines[np.array(['CLB Registers' in line for line in lines])][0].split('|')[2])\n",
    "            data_['bram']    = float(lines[np.array(['Block RAM Tile' in line for line in lines])][0].split('|')[2])\n",
    "            data_['dsp']     = int(lines[np.array(['DSPs' in line for line in lines])][0].split('|')[2])\n",
    "            data_['lut_rel'] = float(lines[np.array(['CLB LUTs*' in line for line in lines])][0].split('|')[5])\n",
    "            data_['ff_rel']  = float(lines[np.array(['CLB Registers' in line for line in lines])][0].split('|')[5])\n",
    "            data_['bram_rel']= float(lines[np.array(['Block RAM Tile' in line for line in lines])][0].split('|')[5])\n",
    "            data_['dsp_rel'] = float(lines[np.array(['DSPs' in line for line in lines])][0].split('|')[5])\n",
    "        \n",
    "        with report_csynth.open() as report:\n",
    "            lines = np.array(report.readlines())\n",
    "            lat_line = lines[np.argwhere(np.array(['Latency (cycles)' in line for line in lines])).flatten()[0] + 3]\n",
    "            data_['latency_clks'] = int(lat_line.split('|')[2])\n",
    "            data_['latency_mus']  = float(lat_line.split('|')[2])*5.0/1000.\n",
    "            data_['latency_ii']   = int(lat_line.split('|')[6])\n",
    "    \n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pprint \n",
    "\n",
    "data_pruned_ref = getReports('pruned_cnn')\n",
    "\n",
    "print(\"\\n Resource usage and latency: Pruned\")\n",
    "pprint.pprint(data_pruned_ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
